import pyodbc
import pandas as pd
from mlxtend.frequent_patterns import apriori, association_rules
from mlxtend.preprocessing import TransactionEncoder
import json
import os
from dotenv import load_dotenv

load_dotenv()

class MarketBasketAnalyzer:
    def __init__(self):
        self.conn_str = (
            f"DRIVER={{ODBC Driver 17 for SQL Server}};"
            f"SERVER={os.getenv('DB_SERVER', os.getenv('DB_HOST'))};"
            f"DATABASE={os.getenv('DB_NAME')};"
            f"UID={os.getenv('DB_USER')};"
            f"PWD={os.getenv('DB_PASSWORD')}"
        )
    
    def get_transactions(self):
        """L·∫•y d·ªØ li·ªáu giao d·ªãch t·ª´ database"""
        query = """
        SELECT 
            o.id as order_id,
            p.name as product_name
        FROM Orders o
        JOIN OrderItems oi ON o.id = oi.order_id
        JOIN Products p ON oi.product_id = p.id
        WHERE o.status IN ('DELIVERED', 'paid', 'delivery')
        ORDER BY o.id
        """
        
        with pyodbc.connect(self.conn_str) as conn:
            df = pd.read_sql(query, conn)
        
        # Chuy·ªÉn ƒë·ªïi th√†nh danh s√°ch transactions
        transactions = df.groupby('order_id')['product_name'].apply(list).values.tolist()
        return transactions
    
    def run_apriori(self, min_support=0.01, min_confidence=0.3, min_lift=1.0):
        """
        Ch·∫°y thu·∫≠t to√°n Apriori
        
        Args:
            min_support: ƒê·ªô h·ªó tr·ª£ t·ªëi thi·ªÉu (0.01 = 1% ƒë∆°n h√†ng)
            min_confidence: ƒê·ªô tin c·∫≠y t·ªëi thi·ªÉu (0.3 = 30%)
            min_lift: Lift t·ªëi thi·ªÉu (1.0 = kh√¥ng ·∫£nh h∆∞·ªüng)
        """
        print(f"üîç ƒêang ph√¢n t√≠ch gi·ªè h√†ng...")
        
        # L·∫•y d·ªØ li·ªáu
        transactions = self.get_transactions()
        print(f"üìä T·ªïng s·ªë ƒë∆°n h√†ng: {len(transactions)}")
        
        # Chuy·ªÉn ƒë·ªïi sang ƒë·ªãnh d·∫°ng one-hot encoding
        te = TransactionEncoder()
        te_ary = te.fit(transactions).transform(transactions)
        df = pd.DataFrame(te_ary, columns=te.columns_)
        
        # T√¨m itemsets ph·ªï bi·∫øn
        frequent_itemsets = apriori(df, min_support=min_support, use_colnames=True)
        print(f"‚úÖ T√¨m th·∫•y {len(frequent_itemsets)} itemsets ph·ªï bi·∫øn")
        
        # T·∫°o lu·∫≠t k·∫øt h·ª£p
        if len(frequent_itemsets) > 0:
            rules = association_rules(
                frequent_itemsets, 
                metric="confidence", 
                min_threshold=min_confidence
            )
            
            # L·ªçc theo lift
            rules = rules[rules['lift'] >= min_lift]
            
            # S·∫Øp x·∫øp theo lift gi·∫£m d·∫ßn
            rules = rules.sort_values('lift', ascending=False)
            
            print(f"‚úÖ T√¨m th·∫•y {len(rules)} lu·∫≠t k·∫øt h·ª£p")
            
            return self._format_results(rules)
        else:
            return {
                'frequent_itemsets': [],
                'rules': [],
                'summary': {
                    'total_transactions': len(transactions),
                    'total_rules': 0
                }
            }
    
    def _format_results(self, rules):
        """Format k·∫øt qu·∫£ ƒë·ªÉ tr·∫£ v·ªÅ API"""
        formatted_rules = []
        
        for _, rule in rules.iterrows():
            formatted_rules.append({
                'antecedents': list(rule['antecedents']),
                'consequents': list(rule['consequents']),
                'support': float(rule['support']),
                'confidence': float(rule['confidence']),
                'lift': float(rule['lift']),
                'description': f"{', '.join(rule['antecedents'])} ‚Üí {', '.join(rule['consequents'])}"
            })
        
        return {
            'rules': formatted_rules,
            'summary': {
                'total_rules': len(formatted_rules),
                'avg_confidence': float(rules['confidence'].mean()),
                'avg_lift': float(rules['lift'].mean())
            }
        }
    
    def get_top_combos(self, limit=10):
        """L·∫•y top N g√≥i h√†ng ƒë∆∞·ª£c mua c√πng nhau nhi·ªÅu nh·∫•t"""
        results = self.run_apriori(min_support=0.01, min_confidence=0.3, min_lift=1.2)
        
        if results['rules']:
            return results['rules'][:limit]
        return []

if __name__ == "__main__":
    analyzer = MarketBasketAnalyzer()
    results = analyzer.run_apriori(min_support=0.01, min_confidence=0.3)
    
    print("\n" + "="*80)
    print("üì¶ TOP 10 G√ìI H√ÄNG TH∆Ø·ªúNG MUA C√ôNG NHAU")
    print("="*80)
    
    for i, rule in enumerate(results['rules'][:10], 1):
        print(f"\n{i}. {rule['description']}")
        print(f"   - ƒê·ªô h·ªó tr·ª£: {rule['support']:.2%}")
        print(f"   - ƒê·ªô tin c·∫≠y: {rule['confidence']:.2%}")
        print(f"   - Lift: {rule['lift']:.2f}")
