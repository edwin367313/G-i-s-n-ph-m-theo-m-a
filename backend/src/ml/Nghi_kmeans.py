import pyodbc
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from datetime import datetime
import joblib
import os
from dotenv import load_dotenv

load_dotenv()

class CustomerSegmentation:
    def __init__(self):
        self.conn_str = (
            f"DRIVER={{ODBC Driver 17 for SQL Server}};"
            f"SERVER={os.getenv('DB_SERVER', os.getenv('DB_HOST'))};"
            f"DATABASE={os.getenv('DB_NAME')};"
            f"UID={os.getenv('DB_USER')};"
            f"PWD={os.getenv('DB_PASSWORD')}"
        )
        self.scaler = StandardScaler()
        self.kmeans = None
    
    def calculate_rfm(self):
        """TÃ­nh toÃ¡n chá»‰ sá»‘ RFM cho tá»«ng khÃ¡ch hÃ ng"""
        query = """
        WITH CustomerOrders AS (
            SELECT 
                user_id,
                MAX(created_at) as last_order_date,
                COUNT(DISTINCT id) as frequency,
                SUM(total_amount) as monetary
            FROM Orders
            WHERE status IN ('DELIVERED', 'paid', 'delivery')
                AND user_id IS NOT NULL
            GROUP BY user_id
        )
        SELECT 
            co.user_id,
            u.full_name,
            u.email,
            u.phone,
            DATEDIFF(day, co.last_order_date, GETDATE()) as recency,
            co.frequency,
            co.monetary,
            co.last_order_date
        FROM CustomerOrders co
        JOIN Users u ON co.user_id = u.id
        WHERE u.role = 'customer'
        """
        
        with pyodbc.connect(self.conn_str) as conn:
            df = pd.read_sql(query, conn)
        
        print(f"ğŸ“Š Tá»•ng sá»‘ khÃ¡ch hÃ ng: {len(df)}")
        return df
    
    def segment_customers(self, n_clusters=3):
        """
        PhÃ¢n cá»¥m khÃ¡ch hÃ ng báº±ng K-Means
        
        Args:
            n_clusters: Sá»‘ cá»¥m (máº·c Ä‘á»‹nh 3: VIP, ThÆ°á»ng xuyÃªn, VÃ£ng lai)
        """
        print(f"ğŸ” Äang phÃ¢n cá»¥m khÃ¡ch hÃ ng thÃ nh {n_clusters} nhÃ³m...")
        
        # TÃ­nh RFM
        df = self.calculate_rfm()
        
        if len(df) == 0:
            return None
        
        # Chuáº©n bá»‹ dá»¯ liá»‡u cho clustering
        rfm_data = df[['recency', 'frequency', 'monetary']].copy()
        
        # Chuáº©n hÃ³a dá»¯ liá»‡u
        rfm_scaled = self.scaler.fit_transform(rfm_data)
        
        # Cháº¡y K-Means
        self.kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        df['cluster'] = self.kmeans.fit_predict(rfm_scaled)
        
        # PhÃ¢n tÃ­ch tá»«ng cá»¥m
        cluster_analysis = self._analyze_clusters(df)
        
        # GÃ¡n nhÃ£n tá»± Ä‘á»™ng
        df = self._auto_label_clusters(df, cluster_analysis)
        
        # LÆ°u model
        self._save_model()
        
        print(f"âœ… ÄÃ£ phÃ¢n cá»¥m thÃ nh cÃ´ng!")
        
        return df, cluster_analysis
    
    def _analyze_clusters(self, df):
        """PhÃ¢n tÃ­ch Ä‘áº·c Ä‘iá»ƒm cá»§a tá»«ng cá»¥m"""
        analysis = []
        
        for cluster_id in sorted(df['cluster'].unique()):
            cluster_df = df[df['cluster'] == cluster_id]
            
            analysis.append({
                'cluster_id': int(cluster_id),
                'size': len(cluster_df),
                'avg_recency': float(cluster_df['recency'].mean()),
                'avg_frequency': float(cluster_df['frequency'].mean()),
                'avg_monetary': float(cluster_df['monetary'].mean()),
                'total_revenue': float(cluster_df['monetary'].sum())
            })
        
        return analysis
    
    def _auto_label_clusters(self, df, cluster_analysis):
        """
        Tá»± Ä‘á»™ng gÃ¡n nhÃ£n cho cÃ¡c cá»¥m dá»±a trÃªn Ä‘áº·c Ä‘iá»ƒm RFM
        
        Logic:
        - VIP: Frequency cao, Monetary cao, Recency tháº¥p
        - ThÆ°á»ng xuyÃªn: Frequency trung bÃ¬nh, Monetary trung bÃ¬nh
        - VÃ£ng lai: Frequency tháº¥p hoáº·c Recency cao
        """
        # TÃ­nh Ä‘iá»ƒm cho má»—i cá»¥m
        cluster_scores = []
        
        for analysis in cluster_analysis:
            # Äiá»ƒm cÃ ng cao = khÃ¡ch hÃ ng cÃ ng tá»‘t
            score = (
                analysis['avg_frequency'] * 0.4 +  # Táº§n suáº¥t mua hÃ ng quan trá»ng
                (analysis['avg_monetary'] / 1000000) * 0.4 +  # Tá»•ng chi tiÃªu
                (1 / (analysis['avg_recency'] + 1)) * 100 * 0.2  # Gáº§n Ä‘Ã¢y (Ä‘áº£o ngÆ°á»£c)
            )
            cluster_scores.append({
                'cluster_id': analysis['cluster_id'],
                'score': score
            })
        
        # Sáº¯p xáº¿p theo Ä‘iá»ƒm
        cluster_scores = sorted(cluster_scores, key=lambda x: x['score'], reverse=True)
        
        # GÃ¡n nhÃ£n
        labels = {
            cluster_scores[0]['cluster_id']: 'VIP',
        }
        
        if len(cluster_scores) == 2:
            labels[cluster_scores[1]['cluster_id']] = 'VÃ£ng lai'
        elif len(cluster_scores) >= 3:
            labels[cluster_scores[1]['cluster_id']] = 'ThÆ°á»ng xuyÃªn'
            labels[cluster_scores[2]['cluster_id']] = 'VÃ£ng lai'
            
            # Náº¿u cÃ³ thÃªm cá»¥m, gá»i lÃ  "Cáº§n chÄƒm sÃ³c"
            for i in range(3, len(cluster_scores)):
                labels[cluster_scores[i]['cluster_id']] = 'Cáº§n chÄƒm sÃ³c'
        
        # Ãp dá»¥ng nhÃ£n vÃ o dataframe
        df['label'] = df['cluster'].map(labels)
        
        return df
    
    def _save_model(self):
        """LÆ°u model vÃ  scaler Ä‘á»ƒ sá»­ dá»¥ng sau"""
        models_dir = os.path.join(os.path.dirname(__file__), 'models')
        os.makedirs(models_dir, exist_ok=True)
        
        joblib.dump(self.kmeans, os.path.join(models_dir, 'kmeans_model.pkl'))
        joblib.dump(self.scaler, os.path.join(models_dir, 'scaler.pkl'))
        print("ğŸ’¾ ÄÃ£ lÆ°u model vÃ o models/")
    
    def predict_customer_segment(self, recency, frequency, monetary):
        """Dá»± Ä‘oÃ¡n phÃ¢n khÃºc cho khÃ¡ch hÃ ng má»›i"""
        if self.kmeans is None:
            self._load_model()
        
        # Chuáº©n hÃ³a dá»¯ liá»‡u
        data = np.array([[recency, frequency, monetary]])
        data_scaled = self.scaler.transform(data)
        
        # Dá»± Ä‘oÃ¡n
        cluster = self.kmeans.predict(data_scaled)[0]
        
        return int(cluster)
    
    def _load_model(self):
        """Load model Ä‘Ã£ lÆ°u"""
        models_dir = os.path.join(os.path.dirname(__file__), 'models')
        
        self.kmeans = joblib.load(os.path.join(models_dir, 'kmeans_model.pkl'))
        self.scaler = joblib.load(os.path.join(models_dir, 'scaler.pkl'))

if __name__ == "__main__":
    segmenter = CustomerSegmentation()
    df, analysis = segmenter.segment_customers(n_clusters=3)
    
    if df is not None:
        print("\n" + "="*80)
        print("ğŸ‘¥ PHÃ‚N TÃCH PHÃ‚N KHÃšC KHÃCH HÃ€NG")
        print("="*80)
        
        for cluster in analysis:
            label = df[df['cluster'] == cluster['cluster_id']]['label'].iloc[0]
            print(f"\nğŸ“Š NhÃ³m {cluster['cluster_id']}: {label}")
            print(f"   - Sá»‘ lÆ°á»£ng: {cluster['size']} khÃ¡ch hÃ ng")
            print(f"   - Recency TB: {cluster['avg_recency']:.0f} ngÃ y")
            print(f"   - Frequency TB: {cluster['avg_frequency']:.1f} Ä‘Æ¡n")
            print(f"   - Monetary TB: {cluster['avg_monetary']:,.0f} Ä‘")
            print(f"   - Tá»•ng doanh thu: {cluster['total_revenue']:,.0f} Ä‘")
        
        # LÆ°u káº¿t quáº£
        output_path = os.path.join(os.path.dirname(__file__), 'data', 'customer_segments.csv')
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        df.to_csv(output_path, index=False, encoding='utf-8-sig')
        print(f"\nğŸ’¾ ÄÃ£ lÆ°u káº¿t quáº£ vÃ o {output_path}")
