import pyodbc
import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
import joblib
import os
from dotenv import load_dotenv

load_dotenv()

class CustomerClassifier:
    def __init__(self):
        self.conn_str = (
            f"DRIVER={{ODBC Driver 17 for SQL Server}};"
            f"SERVER={os.getenv('DB_SERVER', os.getenv('DB_HOST'))};"
            f"DATABASE={os.getenv('DB_DATABASE', os.getenv('DB_NAME'))};"
            f"UID={os.getenv('DB_USER')};"
            f"PWD={os.getenv('DB_PASSWORD')}"
        )
        self.dt_model = None
        self.label_mapping = None
    
    def load_segmented_data(self):
        """Load d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c ph√¢n kh√∫c t·ª´ b∆∞·ªõc 2"""
        data_path = os.path.join(os.path.dirname(__file__), 'data', 'customer_segments.csv')
        
        if not os.path.exists(data_path):
            raise FileNotFoundError("Ch∆∞a c√≥ d·ªØ li·ªáu ph√¢n kh√∫c. H√£y ch·∫°y step2_kmeans.py tr∆∞·ªõc!")
        
        df = pd.read_csv(data_path)
        return df
    
    def prepare_training_data(self):
        """
        Chu·∫©n b·ªã d·ªØ li·ªáu hu·∫•n luy·ªán
        K·∫øt h·ª£p th√¥ng tin kh√°ch h√†ng v·ªõi nh√£n ph√¢n kh√∫c
        """
        # Load d·ªØ li·ªáu ƒë√£ ph√¢n kh√∫c
        df = self.load_segmented_data()
        
        # L·∫•y th√™m th√¥ng tin kh√°ch h√†ng t·ª´ database
        query = """
        SELECT 
            u.id as user_id,
            YEAR(GETDATE()) - YEAR(u.created_at) as account_age_years,
            CASE 
                WHEN u.phone IS NOT NULL AND LEN(u.phone) > 0 THEN 1 
                ELSE 0 
            END as has_phone,
            CASE 
                WHEN u.address IS NOT NULL AND LEN(u.address) > 0 THEN 1 
                ELSE 0 
            END as has_address
        FROM Users u
        WHERE u.role = 'customer'
        """
        
        with pyodbc.connect(self.conn_str) as conn:
            user_info = pd.read_sql(query, conn)
        
        # K·∫øt h·ª£p d·ªØ li·ªáu
        df = df.merge(user_info, on='user_id', how='left')
        
        # T·∫°o th√™m c√°c features
        df['rfm_score'] = (
            (df['recency'].max() - df['recency']) / df['recency'].max() * 0.3 +
            df['frequency'] / df['frequency'].max() * 0.3 +
            df['monetary'] / df['monetary'].max() * 0.4
        )
        
        return df
    
    def train_decision_tree(self, max_depth=5):
        """
        Hu·∫•n luy·ªán Decision Tree v·ªõi nh√£n t·ª´ K-Means
        
        Args:
            max_depth: ƒê·ªô s√¢u t·ªëi ƒëa c·ªßa c√¢y (ƒë·ªÉ d·ªÖ hi·ªÉu)
        """
        print(f"üå≥ ƒêang hu·∫•n luy·ªán Decision Tree...")
        
        # Chu·∫©n b·ªã d·ªØ li·ªáu
        df = self.prepare_training_data()
        
        # Ch·ªçn features
        feature_columns = ['recency', 'frequency', 'monetary', 'account_age_years', 
                          'has_phone', 'has_address', 'rfm_score']
        X = df[feature_columns]
        
        # Target l√† nh√£n ƒë√£ g√°n t·ª´ K-Means
        y = df['label']
        
        # Map label sang s·ªë
        self.label_mapping = {label: idx for idx, label in enumerate(y.unique())}
        reverse_mapping = {idx: label for label, idx in self.label_mapping.items()}
        y_encoded = y.map(self.label_mapping)
        
        # Chia train/test
        X_train, X_test, y_train, y_test = train_test_split(
            X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
        )
        
        # Hu·∫•n luy·ªán
        self.dt_model = DecisionTreeClassifier(
            max_depth=max_depth,
            min_samples_split=5,
            min_samples_leaf=2,
            random_state=42
        )
        self.dt_model.fit(X_train, y_train)
        
        # ƒê√°nh gi√°
        y_pred = self.dt_model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        print(f"‚úÖ ƒê·ªô ch√≠nh x√°c: {accuracy:.2%}")
        
        # In b√°o c√°o chi ti·∫øt
        print("\nüìä B√°o c√°o ph√¢n lo·∫°i:")
        target_names = [reverse_mapping[i] for i in sorted(reverse_mapping.keys())]
        print(classification_report(y_test, y_pred, target_names=target_names))
        
        # L∆∞u model
        self._save_model(feature_columns, reverse_mapping)
        
        # Tr√≠ch xu·∫•t lu·∫≠t
        rules = self._extract_rules(feature_columns, reverse_mapping)
        
        return {
            'accuracy': accuracy,
            'rules': rules,
            'feature_importance': self._get_feature_importance(feature_columns)
        }
    
    def _extract_rules(self, feature_names, label_mapping):
        """Tr√≠ch xu·∫•t lu·∫≠t t·ª´ Decision Tree d∆∞·ªõi d·∫°ng text"""
        tree_rules = export_text(
            self.dt_model, 
            feature_names=feature_names,
            max_depth=5
        )
        
        return tree_rules
    
    def _get_feature_importance(self, feature_names):
        """L·∫•y ƒë·ªô quan tr·ªçng c·ªßa c√°c features"""
        if self.dt_model is None:
            return []
        
        importances = self.dt_model.feature_importances_  # type: ignore
        
        feature_importance = []
        for name, importance in zip(feature_names, importances):
            feature_importance.append({
                'feature': name,
                'importance': float(importance)
            })
        
        # S·∫Øp x·∫øp theo ƒë·ªô quan tr·ªçng
        feature_importance = sorted(
            feature_importance, 
            key=lambda x: x['importance'], 
            reverse=True
        )
        
        return feature_importance
    
    def _save_model(self, feature_columns, label_mapping):
        """L∆∞u model v√† metadata"""
        models_dir = os.path.join(os.path.dirname(__file__), 'models')
        os.makedirs(models_dir, exist_ok=True)
        
        joblib.dump(self.dt_model, os.path.join(models_dir, 'decision_tree.pkl'))
        joblib.dump({
            'feature_columns': feature_columns,
            'label_mapping': label_mapping
        }, os.path.join(models_dir, 'dt_metadata.pkl'))
        
        print("üíæ ƒê√£ l∆∞u Decision Tree model")
    
    def predict_customer_type(self, customer_features):
        """
        D·ª± ƒëo√°n lo·∫°i kh√°ch h√†ng m·ªõi
        
        Args:
            customer_features: dict ch·ª©a c√°c features
        """
        if self.dt_model is None:
            self._load_model()
        
        if self.dt_model is None:
            raise ValueError("Model ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán")
        
        # Load metadata
        models_dir = os.path.join(os.path.dirname(__file__), 'models')
        metadata = joblib.load(os.path.join(models_dir, 'dt_metadata.pkl'))
        
        # Chu·∫©n b·ªã d·ªØ li·ªáu
        X = pd.DataFrame([customer_features])[metadata['feature_columns']]  # type: ignore
        
        # D·ª± ƒëo√°n
        prediction = self.dt_model.predict(X)[0]  # type: ignore
        probabilities = self.dt_model.predict_proba(X)[0]  # type: ignore
        
        # L·∫•y nh√£n
        label = metadata['label_mapping'][prediction]  # type: ignore
        
        # T·∫°o k·∫øt qu·∫£ chi ti·∫øt
        result = {
            'label': label,
            'confidence': float(max(probabilities)),
            'probabilities': {
                metadata['label_mapping'][i]: float(prob)  # type: ignore
                for i, prob in enumerate(probabilities)
            }
        }
        
        return result
    
    def _load_model(self):
        """Load model ƒë√£ l∆∞u"""
        models_dir = os.path.join(os.path.dirname(__file__), 'models')
        self.dt_model = joblib.load(os.path.join(models_dir, 'decision_tree.pkl'))

if __name__ == "__main__":
    classifier = CustomerClassifier()
    
    try:
        results = classifier.train_decision_tree(max_depth=5)
        
        print("\n" + "="*80)
        print("üå≥ LU·∫¨T PH√ÇN LO·∫†I KH√ÅCH H√ÄNG")
        print("="*80)
        print(results['rules'])
        
        print("\n" + "="*80)
        print("üìä ƒê·ªò QUAN TR·ªåNG C√ÅC FEATURES")
        print("="*80)
        for item in results['feature_importance']:
            print(f"  {item['feature']:20s}: {item['importance']:.3f}")
        
    except FileNotFoundError as e:
        print(f"‚ùå L·ªói: {e}")
        print("üí° H√£y ch·∫°y step2_kmeans.py tr∆∞·ªõc ƒë·ªÉ t·∫°o d·ªØ li·ªáu ph√¢n kh√∫c!")
